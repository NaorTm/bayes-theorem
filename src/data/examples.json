[
  {
    "id": "ex01",
    "title": "Medical test, classic base rate",
    "difficulty": "Beginner",
    "tags": [
      "medical",
      "base-rate",
      "discrete"
    ],
    "problemMarkdown": "Disease prevalence p=0.01, sensitivity s=0.95, specificity c=0.92. Compute P(D|+).",
    "variables": {
      "p": 0.01,
      "s": 0.95,
      "c": 0.92
    },
    "definitions": [
      "D: disease",
      "+: positive test"
    ],
    "solutionSteps": [
      {
        "title": "Write Bayes formula",
        "explanationMarkdown": "Posterior equals numerator over evidence denominator.",
        "mathLatex": "P(D\\mid +)=\\frac{P(+\\mid D)P(D)}{P(+)}"
      },
      {
        "title": "Compute denominator explicitly",
        "explanationMarkdown": "Use total probability across diseased and healthy groups.",
        "mathLatex": "P(+)=P(+\\mid D)P(D)+P(+\\mid D^c)P(D^c)=0.95\\cdot0.01+0.08\\cdot0.99=0.0887"
      },
      {
        "title": "Normalize",
        "explanationMarkdown": "Divide the true-positive mass by all positives.",
        "mathLatex": "P(D\\mid +)=\\frac{0.95\\cdot0.01}{0.0887}=0.1071"
      }
    ],
    "visuals": [
      {
        "widget": "matrix",
        "params": {
          "population": 10000
        }
      }
    ],
    "simulationSpec": {
      "seed": 101,
      "samplingFunction": "simulateDiagnosticTest",
      "trials": 100000
    },
    "finalAnswer": {
      "numeric": "0.1071",
      "symbolic": "\\frac{sp}{sp+(1-c)(1-p)}"
    },
    "takeaway": "Even high sensitivity can produce many false positives when prevalence is low."
  },
  {
    "id": "ex02",
    "title": "Two independent tests",
    "difficulty": "Intermediate",
    "tags": [
      "medical",
      "sequential",
      "updating"
    ],
    "problemMarkdown": "Using Example 1 parameters, a second independent test is also positive. Update sequentially.",
    "variables": {
      "priorAfterFirst": 0.1071,
      "s": 0.95,
      "fpr": 0.08
    },
    "definitions": [
      "D: disease",
      "+_1,+_2: first and second positive tests"
    ],
    "solutionSteps": [
      {
        "title": "Posterior after first test",
        "explanationMarkdown": "Use Example 1 as prior for the second update.",
        "mathLatex": "P(D\\mid +_1)=0.1071"
      },
      {
        "title": "Apply Bayes again",
        "explanationMarkdown": "Second test uses same likelihood and false-positive rate.",
        "mathLatex": "P(D\\mid +_1,+_2)=\\frac{0.95\\cdot0.1071}{0.95\\cdot0.1071+0.08\\cdot(1-0.1071)}"
      },
      {
        "title": "Compute",
        "explanationMarkdown": "Sequential update sharply increases posterior.",
        "mathLatex": "P(D\\mid +_1,+_2)=0.5876"
      }
    ],
    "visuals": [
      {
        "widget": "tree",
        "params": {
          "stages": 2
        }
      }
    ],
    "simulationSpec": {
      "seed": 102,
      "samplingFunction": "simulateTwoStageTesting",
      "trials": 50000
    },
    "finalAnswer": {
      "numeric": "0.5876",
      "symbolic": "\\frac{s p_1}{s p_1 + f(1-p_1)}"
    },
    "takeaway": "Posterior from one test becomes the prior for the next piece of evidence."
  },
  {
    "id": "ex03",
    "title": "Quality control",
    "difficulty": "Beginner",
    "tags": [
      "manufacturing",
      "discrete"
    ],
    "problemMarkdown": "Defect rate is 0.02. Sensor catches defects with 0.9 sensitivity and has 0.04 false positive rate. Find P(defect|alarm).",
    "variables": {
      "defectRate": 0.02,
      "sensitivity": 0.9,
      "fpr": 0.04
    },
    "definitions": [
      "D: defective item",
      "A: alarm"
    ],
    "solutionSteps": [
      {
        "title": "Bayes setup",
        "explanationMarkdown": "Treat alarm as evidence.",
        "mathLatex": "P(D\\mid A)=\\frac{P(A\\mid D)P(D)}{P(A)}"
      },
      {
        "title": "Denominator via total probability",
        "explanationMarkdown": "Both defective and non-defective items can trigger alarms.",
        "mathLatex": "P(A)=0.9\\cdot0.02+0.04\\cdot0.98=0.0572"
      },
      {
        "title": "Posterior",
        "explanationMarkdown": "Normalize true alarms by all alarms.",
        "mathLatex": "P(D\\mid A)=0.018/0.0572=0.3147"
      }
    ],
    "visuals": [
      {
        "widget": "area",
        "params": {
          "prior": 0.02
        }
      }
    ],
    "simulationSpec": {
      "seed": 103,
      "samplingFunction": "simulateQualityControl",
      "trials": 100000
    },
    "finalAnswer": {
      "numeric": "0.3147",
      "symbolic": "\\frac{0.9\\cdot0.02}{0.9\\cdot0.02+0.04\\cdot0.98}"
    },
    "takeaway": "Most alarmed units are still good unless the base defect rate is substantial."
  },
  {
    "id": "ex04",
    "title": "Courtroom evidence",
    "difficulty": "Intermediate",
    "tags": [
      "legal",
      "base-rate",
      "odds"
    ],
    "problemMarkdown": "DNA match likelihood if guilty is 0.999; false match if innocent is 0.0001. Prior guilt before DNA is 1/1000. Compute posterior guilt after match.",
    "variables": {
      "prior": 0.001,
      "trueMatch": 0.999,
      "falseMatch": 0.0001
    },
    "definitions": [
      "G: guilty",
      "M: DNA match"
    ],
    "solutionSteps": [
      {
        "title": "Bayes formula",
        "explanationMarkdown": "Compare match likelihood under guilt and innocence.",
        "mathLatex": "P(G\\mid M)=\\frac{P(M\\mid G)P(G)}{P(M)}"
      },
      {
        "title": "Evidence denominator",
        "explanationMarkdown": "Use both guilt and innocence pathways.",
        "mathLatex": "P(M)=0.999\\cdot0.001+0.0001\\cdot0.999=0.0010989"
      },
      {
        "title": "Posterior",
        "explanationMarkdown": "DNA is strong evidence but prior still matters.",
        "mathLatex": "P(G\\mid M)=0.999\\cdot0.001/0.0010989=0.9099"
      }
    ],
    "visuals": [
      {
        "widget": "odds",
        "params": {
          "priorOdds": 0.001001001001001001
        }
      }
    ],
    "simulationSpec": {
      "seed": 104,
      "samplingFunction": "simulateDnaEvidence",
      "trials": 100000
    },
    "finalAnswer": {
      "numeric": "0.9099",
      "symbolic": "\\frac{0.999\\cdot0.001}{0.999\\cdot0.001+0.0001\\cdot0.999}"
    },
    "takeaway": "Likelihood can be huge, yet prior odds still control final certainty."
  },
  {
    "id": "ex05",
    "title": "Spam filtering, discrete toy",
    "difficulty": "Beginner",
    "tags": [
      "classification",
      "text",
      "discrete"
    ],
    "problemMarkdown": "P(Spam)=0.4. Word 'offer' appears with probability 0.2 in spam and 0.03 in ham. Compute P(Spam|offer).",
    "variables": {
      "priorSpam": 0.4,
      "likeSpam": 0.2,
      "likeHam": 0.03
    },
    "definitions": [
      "S: spam",
      "O: word offer appears"
    ],
    "solutionSteps": [
      {
        "title": "Numerator",
        "explanationMarkdown": "Likelihood times prior for spam class.",
        "mathLatex": "P(O\\mid S)P(S)=0.2\\cdot0.4=0.08"
      },
      {
        "title": "Denominator",
        "explanationMarkdown": "Include ham pathway to O.",
        "mathLatex": "P(O)=0.2\\cdot0.4+0.03\\cdot0.6=0.098"
      },
      {
        "title": "Posterior",
        "explanationMarkdown": "Normalize spam contribution by total.",
        "mathLatex": "P(S\\mid O)=0.08/0.098=0.8163"
      }
    ],
    "visuals": [
      {
        "widget": "tree",
        "params": {
          "classes": 2
        }
      }
    ],
    "simulationSpec": {
      "seed": 105,
      "samplingFunction": "simulateWordPresence",
      "trials": 100000
    },
    "finalAnswer": {
      "numeric": "0.8163",
      "symbolic": "\\frac{0.2\\cdot0.4}{0.2\\cdot0.4+0.03\\cdot0.6}"
    },
    "takeaway": "A single informative feature can dominate posterior class probability."
  },
  {
    "id": "ex06",
    "title": "Naive Bayes with log space",
    "difficulty": "Intermediate",
    "tags": [
      "classification",
      "numerical",
      "log-odds"
    ],
    "problemMarkdown": "Classify a message with 20 tokens where each token likelihood is around 1e-3. Explain why log-space is necessary and compute relative class score.",
    "variables": {
      "logScoreSpam": -43.2,
      "logScoreHam": -46.9
    },
    "definitions": [
      "logScore(c)=log P(c)+sum log P(word_i|c)"
    ],
    "solutionSteps": [
      {
        "title": "Why products fail",
        "explanationMarkdown": "Direct product underflows toward machine zero.",
        "mathLatex": "\\prod_{i=1}^{20}10^{-3}=10^{-60}"
      },
      {
        "title": "Use logs",
        "explanationMarkdown": "Convert products to sums for numerical stability.",
        "mathLatex": "\\log score(c)=\\log P(c)+\\sum_i\\log P(w_i\\mid c)"
      },
      {
        "title": "Compare scores",
        "explanationMarkdown": "Higher log score gives larger posterior after normalization.",
        "mathLatex": "-43.2>-46.9\\Rightarrow Spam"
      }
    ],
    "visuals": [
      {
        "widget": "odds",
        "params": {
          "logScale": true
        }
      }
    ],
    "simulationSpec": {
      "seed": 106,
      "samplingFunction": "simulateTokenLikelihoods",
      "trials": 50000
    },
    "finalAnswer": {
      "numeric": "Spam wins by Delta log = 3.7",
      "symbolic": "argmax_c log score(c)"
    },
    "takeaway": "Log domain is standard practice, not optional optimization."
  },
  {
    "id": "ex07",
    "title": "Urn selection",
    "difficulty": "Beginner",
    "tags": [
      "urn",
      "discrete"
    ],
    "problemMarkdown": "Choose urn U1 with probability 0.6 and U2 with probability 0.4. Red-ball probabilities are 0.7 and 0.2. A red ball is observed. Find P(U1|red).",
    "variables": {
      "pU1": 0.6,
      "pRedU1": 0.7,
      "pRedU2": 0.2
    },
    "definitions": [
      "U1,U2: urn selected",
      "R: red draw"
    ],
    "solutionSteps": [
      {
        "title": "Bayes setup",
        "explanationMarkdown": "Urn identity is hypothesis, color is evidence.",
        "mathLatex": "P(U_1\\mid R)=\\frac{P(R\\mid U_1)P(U_1)}{P(R)}"
      },
      {
        "title": "Compute denominator",
        "explanationMarkdown": "Red can come from either urn.",
        "mathLatex": "P(R)=0.7\\cdot0.6+0.2\\cdot0.4=0.5"
      },
      {
        "title": "Posterior",
        "explanationMarkdown": "Normalize U1 red pathway.",
        "mathLatex": "P(U_1\\mid R)=0.42/0.5=0.84"
      }
    ],
    "visuals": [
      {
        "widget": "tree",
        "params": {
          "branches": 2
        }
      }
    ],
    "simulationSpec": {
      "seed": 107,
      "samplingFunction": "simulateUrnDraw",
      "trials": 50000
    },
    "finalAnswer": {
      "numeric": "0.84",
      "symbolic": "\\frac{0.7\\cdot0.6}{0.7\\cdot0.6+0.2\\cdot0.4}"
    },
    "takeaway": "Evidence can strongly favor one prior hypothesis over another."
  },
  {
    "id": "ex08",
    "title": "Box with coins",
    "difficulty": "Intermediate",
    "tags": [
      "coin",
      "sequential"
    ],
    "problemMarkdown": "Box has fair coin (prior 0.7) and biased coin with P(H)=0.8 (prior 0.3). Observe sequence HHT. Find posterior that coin is biased.",
    "variables": {
      "pBiased": 0.3,
      "pSeqBiased": 0.12800000000000003,
      "pSeqFair": 0.125
    },
    "definitions": [
      "B: biased coin chosen",
      "S: observed HHT"
    ],
    "solutionSteps": [
      {
        "title": "Likelihoods",
        "explanationMarkdown": "Compute sequence probability under each coin type.",
        "mathLatex": "P(S\\mid B)=0.8^2\\cdot0.2=0.128,\\;P(S\\mid F)=0.5^3=0.125"
      },
      {
        "title": "Evidence denominator",
        "explanationMarkdown": "Weighted mixture over coin type priors.",
        "mathLatex": "P(S)=0.128\\cdot0.3+0.125\\cdot0.7=0.1259"
      },
      {
        "title": "Posterior",
        "explanationMarkdown": "Biased coin gets slightly higher support.",
        "mathLatex": "P(B\\mid S)=0.0384/0.1259=0.3050"
      }
    ],
    "visuals": [
      {
        "widget": "area",
        "params": {
          "prior": 0.3
        }
      }
    ],
    "simulationSpec": {
      "seed": 108,
      "samplingFunction": "simulateCoinBox",
      "trials": 100000
    },
    "finalAnswer": {
      "numeric": "0.3050",
      "symbolic": "\\frac{0.128\\cdot0.3}{0.128\\cdot0.3+0.125\\cdot0.7}"
    },
    "takeaway": "Posterior shifts only when evidence differentiates likelihoods enough."
  },
  {
    "id": "ex09",
    "title": "Monty Hall as Bayes",
    "difficulty": "Intermediate",
    "tags": [
      "game",
      "conditional"
    ],
    "problemMarkdown": "Contestant picks Door 1. Host opens Door 3 showing goat, with host policy of always opening a goat door and choosing randomly when both options available. Compute P(car behind Door 2 | host opens Door 3).",
    "variables": {
      "priorDoor2": 0.3333333333333333,
      "posteriorDoor2": 0.6666666666666666
    },
    "definitions": [
      "C2: car behind door 2",
      "H3: host opens door 3"
    ],
    "solutionSteps": [
      {
        "title": "Hypotheses",
        "explanationMarkdown": "Possible car locations are door1, door2, door3 with equal priors.",
        "mathLatex": "P(C_i)=1/3"
      },
      {
        "title": "Likelihoods of host action",
        "explanationMarkdown": "If car is door2, host must open door3 (likelihood 1). If car is door1, likelihood 1/2.",
        "mathLatex": "P(H_3\\mid C_2)=1,\\;P(H_3\\mid C_1)=1/2"
      },
      {
        "title": "Posterior",
        "explanationMarkdown": "Normalize over hypotheses consistent with evidence.",
        "mathLatex": "P(C_2\\mid H_3)=\\frac{1\\cdot1/3}{1\\cdot1/3+1/2\\cdot1/3}=2/3"
      }
    ],
    "visuals": [
      {
        "widget": "tree",
        "params": {
          "hostBehavior": true
        }
      }
    ],
    "simulationSpec": {
      "seed": 109,
      "samplingFunction": "simulateMontyHall",
      "trials": 200000
    },
    "finalAnswer": {
      "numeric": "0.6667",
      "symbolic": "2/3"
    },
    "takeaway": "Host policy defines likelihoods, which drive the update."
  },
  {
    "id": "ex10",
    "title": "Sensor fusion, discrete states",
    "difficulty": "Intermediate",
    "tags": [
      "engineering",
      "multi-hypothesis"
    ],
    "problemMarkdown": "Robot state H in {normal, drift, failure} has priors 0.8, 0.15, 0.05. Sensor A reports anomaly with probabilities 0.05, 0.55, 0.9 by state. Sensor B reports anomaly with 0.03,0.5,0.85. Both anomalies observed. Find posterior of failure.",
    "variables": {
      "priors": [
        0.8,
        0.15,
        0.05
      ]
    },
    "definitions": [
      "N,D,F: system states",
      "A+,B+: anomaly flags"
    ],
    "solutionSteps": [
      {
        "title": "Joint likelihood per hypothesis",
        "explanationMarkdown": "Assume conditional independence of sensors given state.",
        "mathLatex": "P(A^+,B^+\\mid H_i)=P(A^+\\mid H_i)P(B^+\\mid H_i)"
      },
      {
        "title": "Evidence denominator over 3 hypotheses",
        "explanationMarkdown": "This is a required multi-hypothesis normalizer.",
        "mathLatex": "P(A^+,B^+)=\\sum_{i\\in\\{N,D,F\\}}P(A^+,B^+\\mid H_i)P(H_i)"
      },
      {
        "title": "Posterior for failure",
        "explanationMarkdown": "Compute weighted failure term over denominator.",
        "mathLatex": "P(F\\mid A^+,B^+)=0.62"
      }
    ],
    "visuals": [
      {
        "widget": "tree",
        "params": {
          "classes": 3
        }
      }
    ],
    "simulationSpec": {
      "seed": 110,
      "samplingFunction": "simulateSensorFusion",
      "trials": 100000
    },
    "finalAnswer": {
      "numeric": "0.62",
      "symbolic": "\\frac{P(A^+,B^+\\mid F)P(F)}{\\sum_iP(A^+,B^+\\mid H_i)P(H_i)}"
    },
    "takeaway": "Multiple moderate sensors can combine into strong posterior evidence."
  },
  {
    "id": "ex11",
    "title": "Reliability, two failure modes",
    "difficulty": "Intermediate",
    "tags": [
      "reliability",
      "engineering"
    ],
    "problemMarkdown": "Failure modes M1 and M2 have priors 0.7 and 0.3 among failures. Signature S occurs with probabilities 0.2 and 0.75 respectively. Given signature S, find P(M2|S).",
    "variables": {
      "pM2": 0.3,
      "pSgivenM2": 0.75
    },
    "definitions": [
      "M1,M2: failure modes",
      "S: observed signature"
    ],
    "solutionSteps": [
      {
        "title": "Numerator",
        "explanationMarkdown": "Signature probability under mode M2 times prior mode share.",
        "mathLatex": "P(S\\mid M_2)P(M_2)=0.75\\cdot0.3=0.225"
      },
      {
        "title": "Denominator",
        "explanationMarkdown": "Both modes can produce S.",
        "mathLatex": "P(S)=0.2\\cdot0.7+0.75\\cdot0.3=0.365"
      },
      {
        "title": "Posterior",
        "explanationMarkdown": "Infer likely failure mode.",
        "mathLatex": "P(M_2\\mid S)=0.225/0.365=0.6164"
      }
    ],
    "visuals": [
      {
        "widget": "matrix",
        "params": {
          "modeCount": 2
        }
      }
    ],
    "simulationSpec": {
      "seed": 111,
      "samplingFunction": "simulateFailureMode",
      "trials": 120000
    },
    "finalAnswer": {
      "numeric": "0.6164",
      "symbolic": "\\frac{0.75\\cdot0.3}{0.75\\cdot0.3+0.2\\cdot0.7}"
    },
    "takeaway": "Posterior diagnosis combines prior mode prevalence and signature specificity."
  },
  {
    "id": "ex12",
    "title": "Communication, bit detection",
    "difficulty": "Intermediate",
    "tags": [
      "communication",
      "signal",
      "discrete"
    ],
    "problemMarkdown": "Bit 1 is sent with prior 0.4 and bit 0 with prior 0.6. Channel flips bits with probability 0.1. Received bit is 1. Find P(sent=1|received=1).",
    "variables": {
      "p1": 0.4,
      "flip": 0.1
    },
    "definitions": [
      "S1: sent bit is 1",
      "R1: received bit is 1"
    ],
    "solutionSteps": [
      {
        "title": "Likelihoods",
        "explanationMarkdown": "P(R1|S1)=0.9 and P(R1|S0)=0.1.",
        "mathLatex": "P(R_1\\mid S_1)=0.9,\\;P(R_1\\mid S_0)=0.1"
      },
      {
        "title": "Denominator",
        "explanationMarkdown": "Received 1 can come from true 1 or flipped 0.",
        "mathLatex": "P(R_1)=0.9\\cdot0.4+0.1\\cdot0.6=0.42"
      },
      {
        "title": "Posterior",
        "explanationMarkdown": "Compute detection confidence.",
        "mathLatex": "P(S_1\\mid R_1)=0.36/0.42=0.8571"
      }
    ],
    "visuals": [
      {
        "widget": "odds",
        "params": {
          "channel": true
        }
      }
    ],
    "simulationSpec": {
      "seed": 112,
      "samplingFunction": "simulateBinaryChannel",
      "trials": 100000
    },
    "finalAnswer": {
      "numeric": "0.8571",
      "symbolic": "\\frac{0.9\\cdot0.4}{0.9\\cdot0.4+0.1\\cdot0.6}"
    },
    "takeaway": "Posterior decoding depends jointly on channel reliability and source prior."
  },
  {
    "id": "ex13",
    "title": "Continuous measurement, Gaussian noise",
    "difficulty": "Intermediate",
    "tags": [
      "continuous",
      "gaussian",
      "inference"
    ],
    "problemMarkdown": "Theta~N(0,4), measurement model X|Theta~N(Theta,1). Observe x=1.5. Compute posterior mean and variance.",
    "variables": {
      "mu0": 0,
      "sigma0": 2,
      "sigma": 1,
      "x": 1.5
    },
    "definitions": [
      "Theta: true value",
      "X: noisy measurement"
    ],
    "solutionSteps": [
      {
        "title": "Posterior variance",
        "explanationMarkdown": "Precisions add in Gaussian conjugacy.",
        "mathLatex": "\\sigma_n^2=(1/4+1)^{-1}=0.8"
      },
      {
        "title": "Posterior mean",
        "explanationMarkdown": "Weighted average of prior mean and observation.",
        "mathLatex": "\\mu_n=0.8(0/4+1.5/1)=1.2"
      },
      {
        "title": "Posterior density",
        "explanationMarkdown": "Resulting posterior is Gaussian.",
        "mathLatex": "\\Theta\\mid x\\sim N(1.2,0.8)"
      }
    ],
    "visuals": [
      {
        "widget": "density",
        "params": {
          "family": "gaussian"
        }
      }
    ],
    "simulationSpec": {
      "seed": 113,
      "samplingFunction": "simulateGaussianUpdate",
      "trials": 20000
    },
    "finalAnswer": {
      "numeric": "mu=1.2, var=0.8",
      "symbolic": "N(1.2,0.8)"
    },
    "takeaway": "Posterior mean shrinks toward prior when measurement noise is non-zero."
  },
  {
    "id": "ex14",
    "title": "Two measurements, sequential update",
    "difficulty": "Intermediate",
    "tags": [
      "continuous",
      "sequential",
      "gaussian"
    ],
    "problemMarkdown": "Use prior Theta~N(0,4), same noise variance 1. Observe x1=1.5 then x2=0.5. Update sequentially.",
    "variables": {
      "mu1": 1.2,
      "var1": 0.8,
      "x2": 0.5
    },
    "definitions": [
      "Posterior after x1 acts as prior for x2"
    ],
    "solutionSteps": [
      {
        "title": "After first observation",
        "explanationMarkdown": "From Example 13, posterior is N(1.2,0.8).",
        "mathLatex": "\\mu_1=1.2,\\;\\sigma_1^2=0.8"
      },
      {
        "title": "Second update",
        "explanationMarkdown": "Combine prior precision 1/0.8 with data precision 1.",
        "mathLatex": "\\sigma_2^2=(1/0.8+1)^{-1}=0.4444"
      },
      {
        "title": "Final mean",
        "explanationMarkdown": "Updated mean balances old belief and new measurement.",
        "mathLatex": "\\mu_2=0.4444(1.2/0.8+0.5)=0.8889"
      }
    ],
    "visuals": [
      {
        "widget": "density",
        "params": {
          "family": "gaussian-seq"
        }
      }
    ],
    "simulationSpec": {
      "seed": 114,
      "samplingFunction": "simulateGaussianSequential",
      "trials": 20000
    },
    "finalAnswer": {
      "numeric": "mu=0.8889, var=0.4444",
      "symbolic": "N(0.8889,0.4444)"
    },
    "takeaway": "Sequential evidence tightens uncertainty and can move the posterior mean."
  },
  {
    "id": "ex15",
    "title": "Beta-Bernoulli, coin bias inference",
    "difficulty": "Intermediate",
    "tags": [
      "beta",
      "bernoulli",
      "continuous"
    ],
    "problemMarkdown": "Prior theta~Beta(2,2). Observe 7 heads and 3 tails. Find posterior and posterior mean.",
    "variables": {
      "alpha": 2,
      "beta": 2,
      "heads": 7,
      "tails": 3
    },
    "definitions": [
      "theta: probability of heads"
    ],
    "solutionSteps": [
      {
        "title": "Conjugate update",
        "explanationMarkdown": "Add successes and failures to prior parameters.",
        "mathLatex": "\\text{Beta}(2,2)+7H+3T\\Rightarrow\\text{Beta}(9,5)"
      },
      {
        "title": "Posterior mean",
        "explanationMarkdown": "Mean of Beta(a,b) is a/(a+b).",
        "mathLatex": "E[\\theta\\mid data]=9/(9+5)=0.6429"
      },
      {
        "title": "Interpretation",
        "explanationMarkdown": "Posterior is centered above 0.5 with moderate concentration.",
        "mathLatex": "\\theta\\mid data\\sim\\text{Beta}(9,5)"
      }
    ],
    "visuals": [
      {
        "widget": "density",
        "params": {
          "family": "beta"
        }
      }
    ],
    "simulationSpec": {
      "seed": 115,
      "samplingFunction": "simulateBetaBernoulli",
      "trials": 30000
    },
    "finalAnswer": {
      "numeric": "Posterior Beta(9,5), mean 0.6429",
      "symbolic": "Beta(\\alpha+k,\\beta+n-k)"
    },
    "takeaway": "Conjugate priors provide transparent and efficient Bayesian updates."
  },
  {
    "id": "ex16",
    "title": "A or B testing, Beta-Binomial",
    "difficulty": "Advanced",
    "tags": [
      "ab-testing",
      "beta",
      "decision"
    ],
    "problemMarkdown": "A: 42 successes of 200. B: 51 successes of 220. Use independent Beta(1,1) priors. Give posteriors and estimate P(thetaA > thetaB).",
    "variables": {
      "aSuccess": 42,
      "aN": 200,
      "bSuccess": 51,
      "bN": 220
    },
    "definitions": [
      "thetaA, thetaB: conversion rates"
    ],
    "solutionSteps": [
      {
        "title": "Posterior parameters",
        "explanationMarkdown": "Apply Beta-Binomial update to each variant.",
        "mathLatex": "\\theta_A\\sim Beta(43,159),\\;\\theta_B\\sim Beta(52,170)"
      },
      {
        "title": "Posterior means",
        "explanationMarkdown": "Compute rough center for each posterior.",
        "mathLatex": "E[\\theta_A]=43/202=0.2129,\\;E[\\theta_B]=52/222=0.2342"
      },
      {
        "title": "Compare via simulation",
        "explanationMarkdown": "Draw paired posterior samples and count thetaA>thetaB.",
        "mathLatex": "P(\\theta_A>\\theta_B\\mid data)\\approx 0.29"
      }
    ],
    "visuals": [
      {
        "widget": "density",
        "params": {
          "family": "beta-pair"
        }
      }
    ],
    "simulationSpec": {
      "seed": 116,
      "samplingFunction": "simulateABPosteriorComparison",
      "draws": 100000
    },
    "finalAnswer": {
      "numeric": "P(thetaA > thetaB) ˜ 0.29",
      "symbolic": "\\int\\int 1_{\\theta_A>\\theta_B}p(\\theta_A)p(\\theta_B)d\\theta_Ad\\theta_B"
    },
    "takeaway": "Bayesian A/B testing returns a direct probability of outperforming, not just a p-value."
  },
  {
    "id": "ex17",
    "title": "Mixture classification, Gaussian mixture",
    "difficulty": "Advanced",
    "tags": [
      "classification",
      "continuous",
      "mixture"
    ],
    "problemMarkdown": "Class C1 prior 0.65 with X|C1~N(0,1). Class C2 prior 0.35 with X|C2~N(2,1). For x=1.2, compute P(C2|x).",
    "variables": {
      "prior1": 0.65,
      "prior2": 0.35,
      "x": 1.2
    },
    "definitions": [
      "C1,C2: classes",
      "X: feature"
    ],
    "solutionSteps": [
      {
        "title": "Class-conditional densities",
        "explanationMarkdown": "Evaluate Gaussian pdf at x=1.2 for each class.",
        "mathLatex": "f_1(1.2)=0.1942,\\;f_2(1.2)=0.2897"
      },
      {
        "title": "Evidence denominator",
        "explanationMarkdown": "Continuous Bayes uses weighted density sum.",
        "mathLatex": "f_X(x)=f_1(x)P(C_1)+f_2(x)P(C_2)"
      },
      {
        "title": "Posterior class probability",
        "explanationMarkdown": "Normalize class C2 weighted density.",
        "mathLatex": "P(C_2\\mid x)=\\frac{f_2(x)P(C_2)}{f_1(x)P(C_1)+f_2(x)P(C_2)}=0.445"
      }
    ],
    "visuals": [
      {
        "widget": "density",
        "params": {
          "family": "mixture"
        }
      }
    ],
    "simulationSpec": {
      "seed": 117,
      "samplingFunction": "simulateGaussianMixtureClassification",
      "trials": 50000
    },
    "finalAnswer": {
      "numeric": "0.445",
      "symbolic": "\\frac{f_2(x)\\pi_2}{f_1(x)\\pi_1+f_2(x)\\pi_2}"
    },
    "takeaway": "In continuous classification, density ratios play the role of likelihood ratios."
  },
  {
    "id": "ex18",
    "title": "Cost-sensitive decision",
    "difficulty": "Advanced",
    "tags": [
      "decision",
      "bayes-factor",
      "loss"
    ],
    "problemMarkdown": "Posterior fraud probability after evidence is 0.04. False block cost is 3, missed fraud cost is 120. Choose action.",
    "variables": {
      "posteriorFraud": 0.04,
      "cFP": 3,
      "cFN": 120
    },
    "definitions": [
      "Action block vs allow"
    ],
    "solutionSteps": [
      {
        "title": "Compute threshold",
        "explanationMarkdown": "Block when posterior > cFP/(cFP+cFN).",
        "mathLatex": "t=3/(3+120)=0.0244"
      },
      {
        "title": "Compare posterior",
        "explanationMarkdown": "Observed posterior exceeds threshold.",
        "mathLatex": "0.04>0.0244"
      },
      {
        "title": "Decision",
        "explanationMarkdown": "Expected loss is lower if we block.",
        "mathLatex": "\\text{Choose block}"
      }
    ],
    "visuals": [
      {
        "widget": "odds",
        "params": {
          "costs": true
        }
      }
    ],
    "simulationSpec": {
      "seed": 118,
      "samplingFunction": "simulateDecisionLoss",
      "trials": 200000
    },
    "finalAnswer": {
      "numeric": "Block",
      "symbolic": "Act if P(Fraud|D) > C_{FP}/(C_{FP}+C_{FN})"
    },
    "takeaway": "Optimal decisions combine posterior belief and asymmetric costs."
  },
  {
    "id": "ex19",
    "title": "Credit risk triage",
    "difficulty": "Intermediate",
    "tags": [
      "finance",
      "multi-hypothesis"
    ],
    "problemMarkdown": "Applicants are low-risk (0.5), medium-risk (0.35), high-risk (0.15). A thin-file flag occurs with probabilities 0.10, 0.35, 0.75 respectively. Compute P(high-risk|flag).",
    "variables": {
      "priors": [
        0.5,
        0.35,
        0.15
      ],
      "likelihoods": [
        0.1,
        0.35,
        0.75
      ]
    },
    "definitions": [
      "L,M,H: risk class",
      "F: thin-file flag"
    ],
    "solutionSteps": [
      {
        "title": "Compute denominator with 3 hypotheses",
        "explanationMarkdown": "Use total probability across all risk classes.",
        "mathLatex": "P(F)=0.10\\cdot0.50+0.35\\cdot0.35+0.75\\cdot0.15=0.285"
      },
      {
        "title": "Compute high-risk numerator",
        "explanationMarkdown": "Weight the high-risk likelihood by prior.",
        "mathLatex": "P(F\\mid H)P(H)=0.75\\cdot0.15=0.1125"
      },
      {
        "title": "Normalize",
        "explanationMarkdown": "Divide by total flag probability.",
        "mathLatex": "P(H\\mid F)=0.1125/0.285=0.3947"
      }
    ],
    "visuals": [
      {
        "widget": "matrix",
        "params": {
          "classes": 3
        }
      }
    ],
    "simulationSpec": {
      "seed": 219,
      "samplingFunction": "simulateCreditRiskFlag",
      "trials": 80000
    },
    "finalAnswer": {
      "numeric": "0.3947",
      "symbolic": "\\frac{P(F\\mid H)P(H)}{\\sum_{c\\in\\{L,M,H\\}}P(F\\mid c)P(c)}"
    },
    "takeaway": "Three-way denominators prevent overconfident risk labeling."
  },
  {
    "id": "ex20",
    "title": "Cyber alert attribution",
    "difficulty": "Advanced",
    "tags": [
      "security",
      "multi-hypothesis"
    ],
    "problemMarkdown": "A critical alert may come from malware (0.12), misconfiguration (0.55), or user error (0.33). Trigger probabilities are 0.85, 0.20, 0.10. Compute P(malware|alert).",
    "variables": {
      "priors": [
        0.12,
        0.55,
        0.33
      ],
      "likelihoods": [
        0.85,
        0.2,
        0.1
      ]
    },
    "definitions": [
      "M: malware",
      "C: misconfig",
      "U: user error",
      "A: critical alert"
    ],
    "solutionSteps": [
      {
        "title": "Evidence denominator",
        "explanationMarkdown": "Sum weighted trigger rates for all causes.",
        "mathLatex": "P(A)=0.85\\cdot0.12+0.20\\cdot0.55+0.10\\cdot0.33=0.245"
      },
      {
        "title": "Malware numerator",
        "explanationMarkdown": "Keep only malware branch mass.",
        "mathLatex": "P(A\\mid M)P(M)=0.85\\cdot0.12=0.102"
      },
      {
        "title": "Posterior",
        "explanationMarkdown": "Normalize to infer incident root cause.",
        "mathLatex": "P(M\\mid A)=0.102/0.245=0.4163"
      }
    ],
    "visuals": [
      {
        "widget": "tree",
        "params": {
          "branches": 3
        }
      }
    ],
    "simulationSpec": {
      "seed": 220,
      "samplingFunction": "simulateCyberAlertAttribution",
      "trials": 120000
    },
    "finalAnswer": {
      "numeric": "0.4163",
      "symbolic": "\\frac{0.85\\cdot0.12}{0.85\\cdot0.12+0.20\\cdot0.55+0.10\\cdot0.33}"
    },
    "takeaway": "Even noisy operational causes must appear in the denominator."
  },
  {
    "id": "ex21",
    "title": "Machine state diagnostics",
    "difficulty": "Intermediate",
    "tags": [
      "engineering",
      "multi-hypothesis"
    ],
    "problemMarkdown": "Machine states are normal (0.70), degraded (0.22), failing (0.08). A vibration alarm appears with probabilities 0.05, 0.40, 0.90. Find P(failing|alarm).",
    "variables": {
      "priors": [
        0.7,
        0.22,
        0.08
      ],
      "likelihoods": [
        0.05,
        0.4,
        0.9
      ]
    },
    "definitions": [
      "N,D,F: state",
      "A: vibration alarm"
    ],
    "solutionSteps": [
      {
        "title": "Denominator by total probability",
        "explanationMarkdown": "Alarm can come from all three states.",
        "mathLatex": "P(A)=0.05\\cdot0.70+0.40\\cdot0.22+0.90\\cdot0.08=0.195"
      },
      {
        "title": "Failing numerator",
        "explanationMarkdown": "Use failing branch only.",
        "mathLatex": "P(A\\mid F)P(F)=0.90\\cdot0.08=0.072"
      },
      {
        "title": "Posterior failing probability",
        "explanationMarkdown": "Normalize branch mass by all alarm mass.",
        "mathLatex": "P(F\\mid A)=0.072/0.195=0.3692"
      }
    ],
    "visuals": [
      {
        "widget": "sankey",
        "params": {
          "classes": 3
        }
      }
    ],
    "simulationSpec": {
      "seed": 221,
      "samplingFunction": "simulateMachineDiagnostics",
      "trials": 100000
    },
    "finalAnswer": {
      "numeric": "0.3692",
      "symbolic": "\\frac{P(A\\mid F)P(F)}{\\sum_{s\\in\\{N,D,F\\}}P(A\\mid s)P(s)}"
    },
    "takeaway": "Posterior risk can rise sharply even when failure prior is small."
  },
  {
    "id": "ex22",
    "title": "Loan default evidence update",
    "difficulty": "Intermediate",
    "tags": [
      "finance",
      "odds"
    ],
    "problemMarkdown": "Prior default probability is 0.08. A payment anomaly has likelihood ratio 4.5 for default vs non-default. Compute posterior default probability using odds form.",
    "variables": {
      "prior": 0.08,
      "bayesFactor": 4.5
    },
    "definitions": [
      "D: default",
      "E: payment anomaly"
    ],
    "solutionSteps": [
      {
        "title": "Convert prior to odds",
        "explanationMarkdown": "Odds form multiplies by Bayes factor.",
        "mathLatex": "O(D)=0.08/0.92=0.08696"
      },
      {
        "title": "Update odds",
        "explanationMarkdown": "Posterior odds equals prior odds times likelihood ratio.",
        "mathLatex": "O(D\\mid E)=4.5\\cdot0.08696=0.3913"
      },
      {
        "title": "Convert back to probability",
        "explanationMarkdown": "Probability is odds over one plus odds.",
        "mathLatex": "P(D\\mid E)=0.3913/(1+0.3913)=0.2813"
      }
    ],
    "visuals": [
      {
        "widget": "odds",
        "params": {
          "likelihoodRatio": 4.5
        }
      }
    ],
    "simulationSpec": {
      "seed": 222,
      "samplingFunction": "simulateLoanDefaultOdds",
      "trials": 70000
    },
    "finalAnswer": {
      "numeric": "0.2813",
      "symbolic": "\\frac{BF\\cdot O(D)}{1+BF\\cdot O(D)}"
    },
    "takeaway": "Odds form makes Bayes-factor updates quick and interpretable."
  },
  {
    "id": "ex23",
    "title": "Airport screening",
    "difficulty": "Intermediate",
    "tags": [
      "security",
      "base-rate"
    ],
    "problemMarkdown": "Threat prevalence is 0.0005. Scanner sensitivity is 0.97 and false positive rate is 0.015. Find P(threat|positive scan).",
    "variables": {
      "prevalence": 0.0005,
      "sensitivity": 0.97,
      "fpr": 0.015
    },
    "definitions": [
      "T: true threat",
      "+: positive scan"
    ],
    "solutionSteps": [
      {
        "title": "Compute evidence",
        "explanationMarkdown": "Positive scans come from true and false positives.",
        "mathLatex": "P(+)=0.97\\cdot0.0005+0.015\\cdot0.9995=0.0154775"
      },
      {
        "title": "True-positive numerator",
        "explanationMarkdown": "Weight sensitivity by threat prevalence.",
        "mathLatex": "P(+\\mid T)P(T)=0.97\\cdot0.0005=0.000485"
      },
      {
        "title": "Posterior",
        "explanationMarkdown": "Normalize by total positive rate.",
        "mathLatex": "P(T\\mid +)=0.000485/0.0154775=0.0313"
      }
    ],
    "visuals": [
      {
        "widget": "matrix",
        "params": {
          "population": 100000
        }
      }
    ],
    "simulationSpec": {
      "seed": 223,
      "samplingFunction": "simulateAirportScreening",
      "trials": 200000
    },
    "finalAnswer": {
      "numeric": "0.0313",
      "symbolic": "\\frac{0.97\\cdot0.0005}{0.97\\cdot0.0005+0.015\\cdot0.9995}"
    },
    "takeaway": "Low prevalence keeps most positives false despite strong sensitivity."
  },
  {
    "id": "ex24",
    "title": "Smart thermostat occupancy",
    "difficulty": "Intermediate",
    "tags": [
      "everyday",
      "sensor"
    ],
    "problemMarkdown": "Home occupancy prior is 0.35. Motion trigger probability is 0.88 if occupied and 0.18 if empty. Compute P(occupied|motion).",
    "variables": {
      "prior": 0.35,
      "likeOcc": 0.88,
      "likeEmpty": 0.18
    },
    "definitions": [
      "O: occupied",
      "M: motion trigger"
    ],
    "solutionSteps": [
      {
        "title": "Denominator",
        "explanationMarkdown": "Motion can happen when occupied or empty.",
        "mathLatex": "P(M)=0.88\\cdot0.35+0.18\\cdot0.65=0.425"
      },
      {
        "title": "Numerator",
        "explanationMarkdown": "Occupied-motion branch mass.",
        "mathLatex": "P(M\\mid O)P(O)=0.88\\cdot0.35=0.308"
      },
      {
        "title": "Posterior occupancy",
        "explanationMarkdown": "Normalize occupied branch.",
        "mathLatex": "P(O\\mid M)=0.308/0.425=0.7247"
      }
    ],
    "visuals": [
      {
        "widget": "tree",
        "params": {
          "stages": 2
        }
      }
    ],
    "simulationSpec": {
      "seed": 224,
      "samplingFunction": "simulateOccupancySensor",
      "trials": 90000
    },
    "finalAnswer": {
      "numeric": "0.7247",
      "symbolic": "\\frac{0.88\\cdot0.35}{0.88\\cdot0.35+0.18\\cdot0.65}"
    },
    "takeaway": "A moderately noisy sensor can still yield strong posterior occupancy."
  },
  {
    "id": "ex25",
    "title": "Market regime inference",
    "difficulty": "Advanced",
    "tags": [
      "finance",
      "continuous",
      "multi-hypothesis"
    ],
    "problemMarkdown": "Regimes: bull(0.45), neutral(0.35), bear(0.20). Observed daily return x=−1.2%. Densities at x are 10.2, 24.0, 31.5 for bull, neutral, bear. Compute P(bear|x).",
    "variables": {
      "priors": [
        0.45,
        0.35,
        0.2
      ],
      "densities": [
        10.2,
        24,
        31.5
      ]
    },
    "definitions": [
      "B,N,R: market regime",
      "X: return"
    ],
    "solutionSteps": [
      {
        "title": "Continuous evidence",
        "explanationMarkdown": "Use weighted density sum, not probability mass.",
        "mathLatex": "f_X(x)=10.2\\cdot0.45+24.0\\cdot0.35+31.5\\cdot0.20=19.29"
      },
      {
        "title": "Bear numerator",
        "explanationMarkdown": "Weight bear density by prior.",
        "mathLatex": "f(x\\mid R)P(R)=31.5\\cdot0.20=6.30"
      },
      {
        "title": "Posterior bear regime",
        "explanationMarkdown": "Normalize by total weighted density.",
        "mathLatex": "P(R\\mid x)=6.30/19.29=0.3266"
      }
    ],
    "visuals": [
      {
        "widget": "density",
        "params": {
          "classes": 3
        }
      }
    ],
    "simulationSpec": {
      "seed": 225,
      "samplingFunction": "simulateMarketRegime",
      "trials": 100000
    },
    "finalAnswer": {
      "numeric": "0.3266",
      "symbolic": "\\frac{f(x\\mid R)P(R)}{\\sum_j f(x\\mid H_j)P(H_j)}"
    },
    "takeaway": "Continuous Bayes still depends on the same denominator logic."
  },
  {
    "id": "ex26",
    "title": "Anomaly triage in logs",
    "difficulty": "Intermediate",
    "tags": [
      "security",
      "classification"
    ],
    "problemMarkdown": "Prior incident probability is 0.02. A rare signature appears with probability 0.70 in incidents and 0.04 in benign traffic. Compute P(incident|signature).",
    "variables": {
      "prior": 0.02,
      "likeIncident": 0.7,
      "likeBenign": 0.04
    },
    "definitions": [
      "I: true incident",
      "S: signature appears"
    ],
    "solutionSteps": [
      {
        "title": "Denominator",
        "explanationMarkdown": "Signature comes from incident and benign traffic.",
        "mathLatex": "P(S)=0.70\\cdot0.02+0.04\\cdot0.98=0.0532"
      },
      {
        "title": "Incident numerator",
        "explanationMarkdown": "Incident branch contributes true signal mass.",
        "mathLatex": "P(S\\mid I)P(I)=0.70\\cdot0.02=0.014"
      },
      {
        "title": "Posterior",
        "explanationMarkdown": "Normalize to get incident probability after alert.",
        "mathLatex": "P(I\\mid S)=0.014/0.0532=0.2632"
      }
    ],
    "visuals": [
      {
        "widget": "odds",
        "params": {
          "logScale": true
        }
      }
    ],
    "simulationSpec": {
      "seed": 226,
      "samplingFunction": "simulateLogAnomaly",
      "trials": 120000
    },
    "finalAnswer": {
      "numeric": "0.2632",
      "symbolic": "\\frac{0.70\\cdot0.02}{0.70\\cdot0.02+0.04\\cdot0.98}"
    },
    "takeaway": "Good signatures can still leave nontrivial false alert volume."
  },
  {
    "id": "ex27",
    "title": "Battery health from voltage",
    "difficulty": "Advanced",
    "tags": [
      "engineering",
      "continuous"
    ],
    "problemMarkdown": "Battery state of charge prior is Normal(60, 12²). Measurement model is X|theta ~ Normal(theta, 8²). Observed voltage implies x=72. Compute posterior mean and variance.",
    "variables": {
      "mu0": 60,
      "sigma0": 12,
      "sigma": 8,
      "x": 72
    },
    "definitions": [
      "theta: true state of charge",
      "X: noisy measurement"
    ],
    "solutionSteps": [
      {
        "title": "Posterior precision",
        "explanationMarkdown": "Add prior and likelihood precisions.",
        "mathLatex": "\\sigma_n^2=1/(1/12^2+1/8^2)=44.3077"
      },
      {
        "title": "Posterior mean",
        "explanationMarkdown": "Weighted average by precision.",
        "mathLatex": "\\mu_n=\\sigma_n^2(60/12^2+72/8^2)=68.3077"
      },
      {
        "title": "Interpret shrinkage",
        "explanationMarkdown": "Posterior moves toward the observation with reduced uncertainty.",
        "mathLatex": "\\theta\\mid x\\sim\\mathcal{N}(68.3077,44.3077)"
      }
    ],
    "visuals": [
      {
        "widget": "density",
        "params": {
          "family": "gaussian-update"
        }
      }
    ],
    "simulationSpec": {
      "seed": 227,
      "samplingFunction": "simulateBatteryMeasurement",
      "trials": 60000
    },
    "finalAnswer": {
      "numeric": "mean 68.3077, variance 44.3077",
      "symbolic": "\\mu_n=\\frac{\\mu_0/\\sigma_0^2+x/\\sigma^2}{1/\\sigma_0^2+1/\\sigma^2}"
    },
    "takeaway": "Conjugate Gaussian updates produce closed-form posteriors instantly."
  },
  {
    "id": "ex28",
    "title": "Weather umbrella decision",
    "difficulty": "Beginner",
    "tags": [
      "everyday",
      "decision",
      "odds"
    ],
    "problemMarkdown": "Forecast app shows a dark-cloud signal. Prior rain chance is 0.25. Signal likelihoods are 0.80 if rain and 0.30 if no rain. Should you carry umbrella if wet-cost is 12 and carry-cost is 2?",
    "variables": {
      "prior": 0.25,
      "likeRain": 0.8,
      "likeDry": 0.3,
      "wetCost": 12,
      "carryCost": 2
    },
    "definitions": [
      "R: rain",
      "D: dark-cloud signal"
    ],
    "solutionSteps": [
      {
        "title": "Posterior rain probability",
        "explanationMarkdown": "Compute Bayes update from signal.",
        "mathLatex": "P(R\\mid D)=\\frac{0.80\\cdot0.25}{0.80\\cdot0.25+0.30\\cdot0.75}=0.4706"
      },
      {
        "title": "Expected loss if no umbrella",
        "explanationMarkdown": "No-umbrella loss equals posterior rain chance times wet cost.",
        "mathLatex": "L_{no}=0.4706\\cdot12=5.6472"
      },
      {
        "title": "Choose lower-loss action",
        "explanationMarkdown": "Carry umbrella cost is fixed at 2.",
        "mathLatex": "L_{carry}=2<5.6472\\Rightarrow \\text{carry umbrella}"
      }
    ],
    "visuals": [
      {
        "widget": "odds",
        "params": {
          "costs": true
        }
      }
    ],
    "simulationSpec": {
      "seed": 228,
      "samplingFunction": "simulateUmbrellaDecision",
      "trials": 50000
    },
    "finalAnswer": {
      "numeric": "Carry umbrella",
      "symbolic": "Choose carry when C_{carry}<P(R\\mid D)\\cdot C_{wet}"
    },
    "takeaway": "Bayesian decisions depend on posterior and utility, not probability alone."
  },
  {
    "id": "ex29",
    "title": "Inventory demand class",
    "difficulty": "Intermediate",
    "tags": [
      "operations",
      "classification"
    ],
    "problemMarkdown": "A product is low-demand (0.50), medium-demand (0.30), or high-demand (0.20). Early sales spike probability is 0.20, 0.45, 0.80 respectively. Compute P(high-demand|spike).",
    "variables": {
      "priors": [
        0.5,
        0.3,
        0.2
      ],
      "likelihoods": [
        0.2,
        0.45,
        0.8
      ]
    },
    "definitions": [
      "L,M,H: demand class",
      "S: early sales spike"
    ],
    "solutionSteps": [
      {
        "title": "Evidence denominator",
        "explanationMarkdown": "Spike can be generated by each demand class.",
        "mathLatex": "P(S)=0.20\\cdot0.50+0.45\\cdot0.30+0.80\\cdot0.20=0.395"
      },
      {
        "title": "High-demand numerator",
        "explanationMarkdown": "Weighted high-demand spike mass.",
        "mathLatex": "P(S\\mid H)P(H)=0.80\\cdot0.20=0.16"
      },
      {
        "title": "Posterior",
        "explanationMarkdown": "Normalize and interpret for stocking decision.",
        "mathLatex": "P(H\\mid S)=0.16/0.395=0.4051"
      }
    ],
    "visuals": [
      {
        "widget": "tree",
        "params": {
          "classes": 3
        }
      }
    ],
    "simulationSpec": {
      "seed": 229,
      "samplingFunction": "simulateInventoryClass",
      "trials": 75000
    },
    "finalAnswer": {
      "numeric": "0.4051",
      "symbolic": "\\frac{0.80\\cdot0.20}{0.20\\cdot0.50+0.45\\cdot0.30+0.80\\cdot0.20}"
    },
    "takeaway": "Early sales signals can meaningfully re-rank demand scenarios."
  },
  {
    "id": "ex30",
    "title": "Fraud ring detection",
    "difficulty": "Advanced",
    "tags": [
      "security",
      "network",
      "multi-hypothesis"
    ],
    "problemMarkdown": "A suspicious transfer could be from solo fraud (0.25), coordinated ring (0.10), or benign anomaly (0.65). Link-analysis hit probabilities are 0.35, 0.90, 0.08. Compute P(ring|link-hit).",
    "variables": {
      "priors": [
        0.25,
        0.1,
        0.65
      ],
      "likelihoods": [
        0.35,
        0.9,
        0.08
      ]
    },
    "definitions": [
      "S: solo fraud",
      "R: ring fraud",
      "B: benign",
      "L: link-analysis hit"
    ],
    "solutionSteps": [
      {
        "title": "Compute denominator",
        "explanationMarkdown": "Link-hit mass from all three explanations.",
        "mathLatex": "P(L)=0.35\\cdot0.25+0.90\\cdot0.10+0.08\\cdot0.65=0.2295"
      },
      {
        "title": "Ring numerator",
        "explanationMarkdown": "Keep ring pathway contribution.",
        "mathLatex": "P(L\\mid R)P(R)=0.90\\cdot0.10=0.09"
      },
      {
        "title": "Posterior ring probability",
        "explanationMarkdown": "Normalize to estimate coordination risk.",
        "mathLatex": "P(R\\mid L)=0.09/0.2295=0.3922"
      }
    ],
    "visuals": [
      {
        "widget": "matrix",
        "params": {
          "classes": 3
        }
      }
    ],
    "simulationSpec": {
      "seed": 230,
      "samplingFunction": "simulateFraudRingSignal",
      "trials": 150000
    },
    "finalAnswer": {
      "numeric": "0.3922",
      "symbolic": "\\frac{P(L\\mid R)P(R)}{P(L\\mid S)P(S)+P(L\\mid R)P(R)+P(L\\mid B)P(B)}"
    },
    "takeaway": "Strong link evidence can elevate ring risk without making it certain."
  }
]
